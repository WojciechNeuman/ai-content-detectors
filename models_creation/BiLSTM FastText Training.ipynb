{"cells":[{"cell_type":"markdown","id":"6e08bc6c","metadata":{"id":"6e08bc6c"},"source":["# BilSTM with FastText word-embeddings Training"]},{"cell_type":"markdown","id":"0e1df9cd","metadata":{"id":"0e1df9cd"},"source":["## Dataset loading"]},{"cell_type":"markdown","id":"2lJUIgCsgs83","metadata":{"id":"2lJUIgCsgs83"},"source":["5k Sample set:\n","\n","train\n","https://drive.google.com/file/d/19t64Y_q5X9_2XkcePFCloFeMGj-zziDc/view?usp=drive_link\n","\n","test\n","https://drive.google.com/file/d/1GgUb75IjJYkFygqWHZWiTiSZ9htWXsG-/view?usp=sharing\n","\n","valid\n","https://drive.google.com/file/d/1Rq3OpD0ZfQ23zrJntAb-5X9p3GeQCVBy/view?usp=drive_link\n","\n","\n","All data set:\n","\n","train\n","https://drive.google.com/file/d/1cA6QNMauKvZr4W62UZS9ysgrGEbURg7Y/view?usp=drive_link\n","\n","test\n","https://drive.google.com/file/d/1hja3qBUB8BvTbhtpuaPHDkuvKOuOda7M/view?usp=drive_link\n","\n","valid\n","https://drive.google.com/file/d/1f6p93RDkV9AeaWcprzKMGKjtgQr0opU0/view?usp=sharing\n","\n","New all data set:\n","\n","train\n","https://drive.google.com/file/d/1mNUOXt3ZiERCH401TkSGXx7-LpbmbMaK/view?usp=sharing\n","\n","test\n","https://drive.google.com/file/d/16p0td9GgJRb9AP8i4HlX-xZGI2u849uA/view?usp=sharing\n","\n","valid\n","https://drive.google.com/file/d/1FhT3m_ApKzX615JzshB5-d-j6S91-6oz/view?usp=sharing"]},{"cell_type":"code","execution_count":null,"id":"KgvBMguefVO0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13560,"status":"ok","timestamp":1735577903365,"user":{"displayName":"Wojciech Neuman","userId":"02532032841570570568"},"user_tz":-60},"id":"KgvBMguefVO0","outputId":"a5b8bd52-b316-4a12-a127-898dd37b8bf8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From (original): https://drive.google.com/uc?id=1mNUOXt3ZiERCH401TkSGXx7-LpbmbMaK\n","From (redirected): https://drive.google.com/uc?id=1mNUOXt3ZiERCH401TkSGXx7-LpbmbMaK&confirm=t&uuid=923af61e-1966-4882-a93a-2865f5266e5e\n","To: /content/train.jsonl\n","100% 292M/292M [00:02<00:00, 141MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1FhT3m_ApKzX615JzshB5-d-j6S91-6oz\n","To: /content/valid.jsonl\n","100% 55.1M/55.1M [00:00<00:00, 93.0MB/s]\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/http/client.py\", line 1375, in getresponse\n","    response.begin()\n","  File \"/usr/lib/python3.10/http/client.py\", line 318, in begin\n","    version, status, reason = self._read_status()\n","  File \"/usr/lib/python3.10/http/client.py\", line 279, in _read_status\n","    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n","  File \"/usr/lib/python3.10/socket.py\", line 705, in readinto\n","    return self._sock.recv_into(b)\n","  File \"/usr/lib/python3.10/ssl.py\", line 1303, in recv_into\n","    return self.read(nbytes, buffer)\n","  File \"/usr/lib/python3.10/ssl.py\", line 1159, in read\n","    return self._sslobj.read(len, buffer)\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/gdown\", line 8, in <module>\n","    sys.exit(main())\n","  File \"/usr/local/lib/python3.10/dist-packages/gdown/__main__.py\", line 172, in main\n","    download(\n","  File \"/usr/local/lib/python3.10/dist-packages/gdown/download.py\", line 202, in download\n","    res = sess.get(url, stream=True, verify=verify)\n","  File \"/usr/local/lib/python3.10/dist-packages/requests/sessions.py\", line 602, in get\n","    return self.request(\"GET\", url, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/requests/sessions.py\", line 589, in request\n","    resp = self.send(prep, **send_kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/requests/sessions.py\", line 703, in send\n","    r = adapter.send(request, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/requests/adapters.py\", line 667, in send\n","    resp = conn.urlopen(\n","  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 789, in urlopen\n","    response = self._make_request(\n","  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connectionpool.py\", line 536, in _make_request\n","    response = conn.getresponse()\n","  File \"/usr/local/lib/python3.10/dist-packages/urllib3/connection.py\", line 507, in getresponse\n","    httplib_response = super().getresponse()\n","  File \"/usr/lib/python3.10/http/client.py\", line 1391, in getresponse\n","    response.close()\n","  File \"/usr/lib/python3.10/http/client.py\", line 419, in close\n","    super().close() # set \"closed\" flag\n","KeyboardInterrupt\n","^C\n","mv: cannot stat 'test.jsonl': No such file or directory\n"]}],"source":["# All training dataset\n","! gdown 1mNUOXt3ZiERCH401TkSGXx7-LpbmbMaK # new all train\n","! gdown 1FhT3m_ApKzX615JzshB5-d-j6S91-6oz # new all valid\n","! gdown 16p0td9GgJRb9AP8i4HlX-xZGI2u849uA # new all test\n","\n","\n","! mkdir open_llm\n","! mv train.jsonl valid.jsonl test.jsonl open_llm/"]},{"cell_type":"code","execution_count":null,"id":"qapaJvjGuvOT","metadata":{"id":"qapaJvjGuvOT"},"outputs":[],"source":["! mkdir models # used for saving models"]},{"cell_type":"markdown","source":["## Library Installation"],"metadata":{"id":"JXJLFM2Dmzk1"},"id":"JXJLFM2Dmzk1"},{"cell_type":"code","execution_count":null,"id":"14490533","metadata":{"id":"14490533"},"outputs":[],"source":["# Standard library imports\n","import os\n","import re\n","import time\n","import random\n","import string\n","import gc\n","import pickle\n","import json\n","\n","# Third-party imports\n","import nltk\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm, tqdm_notebook\n","from nltk.tokenize import word_tokenize\n","from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n","\n","# PyTorch imports\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler\n","from torch.cuda.amp import autocast, GradScaler"]},{"cell_type":"code","source":["import warnings\n","warnings.filterwarnings(\"ignore\", category=FutureWarning)"],"metadata":{"id":"z0ulPjV-yZDl"},"id":"z0ulPjV-yZDl","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"SBpgNYtvkf57","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":254,"status":"ok","timestamp":1735578817664,"user":{"displayName":"Wojciech Neuman","userId":"02532032841570570568"},"user_tz":-60},"id":"SBpgNYtvkf57","outputId":"828afc68-9981-4262-fa62-a19ff9c878be"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":8}],"source":["from nltk.corpus import stopwords\n","\n","nltk.download('stopwords')\n","\n","STOPWORDS = set(stopwords.words('english'))\n","\n","nltk.download('punkt_tab')"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Path to save files in Google Drive\n","drive_path = '/content/drive/MyDrive/Thesis/Models/LSTM/'\n","\n","# Ensure the folder exists\n","os.makedirs(drive_path, exist_ok=True)"],"metadata":{"id":"AnAitfysfKop","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735578835130,"user_tz":-60,"elapsed":17468,"user":{"displayName":"Wojciech Neuman","userId":"02532032841570570568"}},"outputId":"68fdb5a9-c046-4f1d-bd17-0ca721d9d61b"},"id":"AnAitfysfKop","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["## Choose runtime environment"],"metadata":{"id":"jveRSuOBxPXy"},"id":"jveRSuOBxPXy"},{"cell_type":"code","source":["# Check if CUDA (GPU) is available\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    gpu_name = torch.cuda.get_device_name(0)\n","    gpu_capability = torch.cuda.get_device_properties(0).major, torch.cuda.get_device_properties(0).minor\n","    print(f\"Using GPU: {gpu_name}\")\n","    print(f\"Compute Capability: {gpu_capability}\")\n","    print(f\"CUDA Device Count: {torch.cuda.device_count()}\")\n","    print(f\"Memory Allocated: {torch.cuda.memory_allocated(0)} bytes\")\n","    print(f\"Memory Reserved: {torch.cuda.memory_reserved(0)} bytes\")\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"Using CPU\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oPxbgMFWxPq7","executionInfo":{"status":"ok","timestamp":1735578835327,"user_tz":-60,"elapsed":209,"user":{"displayName":"Wojciech Neuman","userId":"02532032841570570568"}},"outputId":"017df1f5-5e39-421a-9f25-161f29d448cc"},"id":"oPxbgMFWxPq7","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using GPU: Tesla T4\n","Compute Capability: (7, 5)\n","CUDA Device Count: 1\n","Memory Allocated: 0 bytes\n","Memory Reserved: 0 bytes\n"]}]},{"cell_type":"markdown","id":"94226d9d","metadata":{"id":"94226d9d"},"source":["## Data preparation"]},{"cell_type":"code","execution_count":null,"id":"1547a43f","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":563},"executionInfo":{"elapsed":3066,"status":"ok","timestamp":1735578838392,"user":{"displayName":"Wojciech Neuman","userId":"02532032841570570568"},"user_tz":-60},"id":"1547a43f","outputId":"8b6dd287-fc74-4c2a-f81b-d507b7dd72e2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                              uid  \\\n","0           [urlsf_subset00]-[15]   \n","1           [urlsf_subset00]-[15]   \n","2           [urlsf_subset00]-[83]   \n","3           [urlsf_subset00]-[83]   \n","4           [urlsf_subset00]-[89]   \n","...                           ...   \n","120929  [urlsf_subset06]-[390176]   \n","120930  [urlsf_subset06]-[390305]   \n","120931  [urlsf_subset06]-[390305]   \n","120932  [urlsf_subset06]-[390316]   \n","120933  [urlsf_subset06]-[390316]   \n","\n","                                                     text  \\\n","0       The dangers of Illinois as a ‘right to work’ s...   \n","1       The governor of Illinois, Gov. Rauner, has req...   \n","2       Check current weather conditions\\n\\nIt’s going...   \n","3       Check current weather conditions It’s going to...   \n","4       On Thursday, the president of the United State...   \n","...                                                   ...   \n","120929  Diego Maradona has paid tribute to the late Al...   \n","120930  Tymee Holds A Guerilla Performance\\n\\n[by Yanc...   \n","120931  Tymee Holds A Guerilla Performance\\n\\n[by Yanc...   \n","120932  South Korea President Moon Jae-in requested a ...   \n","120933  President Moon Jae-in of South Korea spoke wit...   \n","\n","                                               extra   source  label  \n","0       {'source': 'openweb', 'variant': 'original'}  openweb      0  \n","1       {'source': 'chatgpt', 'variant': 'original'}  chatgpt      1  \n","2       {'source': 'openweb', 'variant': 'original'}  openweb      0  \n","3         {'variant': 'original', 'source': 'llama'}    llama      1  \n","4       {'source': 'openweb', 'variant': 'original'}  openweb      0  \n","...                                              ...      ...    ...  \n","120929  {'source': 'chatgpt', 'variant': 'original'}  chatgpt      1  \n","120930  {'source': 'openweb', 'variant': 'original'}  openweb      0  \n","120931    {'variant': 'original', 'source': 'llama'}    llama      1  \n","120932  {'source': 'openweb', 'variant': 'original'}  openweb      0  \n","120933  {'source': 'chatgpt', 'variant': 'original'}  chatgpt      1  \n","\n","[120934 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-0058e1ad-e0ae-45fc-8c3e-f40ee84e3568\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>uid</th>\n","      <th>text</th>\n","      <th>extra</th>\n","      <th>source</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[urlsf_subset00]-[15]</td>\n","      <td>The dangers of Illinois as a ‘right to work’ s...</td>\n","      <td>{'source': 'openweb', 'variant': 'original'}</td>\n","      <td>openweb</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[urlsf_subset00]-[15]</td>\n","      <td>The governor of Illinois, Gov. Rauner, has req...</td>\n","      <td>{'source': 'chatgpt', 'variant': 'original'}</td>\n","      <td>chatgpt</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[urlsf_subset00]-[83]</td>\n","      <td>Check current weather conditions\\n\\nIt’s going...</td>\n","      <td>{'source': 'openweb', 'variant': 'original'}</td>\n","      <td>openweb</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[urlsf_subset00]-[83]</td>\n","      <td>Check current weather conditions It’s going to...</td>\n","      <td>{'variant': 'original', 'source': 'llama'}</td>\n","      <td>llama</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[urlsf_subset00]-[89]</td>\n","      <td>On Thursday, the president of the United State...</td>\n","      <td>{'source': 'openweb', 'variant': 'original'}</td>\n","      <td>openweb</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>120929</th>\n","      <td>[urlsf_subset06]-[390176]</td>\n","      <td>Diego Maradona has paid tribute to the late Al...</td>\n","      <td>{'source': 'chatgpt', 'variant': 'original'}</td>\n","      <td>chatgpt</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>120930</th>\n","      <td>[urlsf_subset06]-[390305]</td>\n","      <td>Tymee Holds A Guerilla Performance\\n\\n[by Yanc...</td>\n","      <td>{'source': 'openweb', 'variant': 'original'}</td>\n","      <td>openweb</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>120931</th>\n","      <td>[urlsf_subset06]-[390305]</td>\n","      <td>Tymee Holds A Guerilla Performance\\n\\n[by Yanc...</td>\n","      <td>{'variant': 'original', 'source': 'llama'}</td>\n","      <td>llama</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>120932</th>\n","      <td>[urlsf_subset06]-[390316]</td>\n","      <td>South Korea President Moon Jae-in requested a ...</td>\n","      <td>{'source': 'openweb', 'variant': 'original'}</td>\n","      <td>openweb</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>120933</th>\n","      <td>[urlsf_subset06]-[390316]</td>\n","      <td>President Moon Jae-in of South Korea spoke wit...</td>\n","      <td>{'source': 'chatgpt', 'variant': 'original'}</td>\n","      <td>chatgpt</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>120934 rows × 5 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0058e1ad-e0ae-45fc-8c3e-f40ee84e3568')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-0058e1ad-e0ae-45fc-8c3e-f40ee84e3568 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-0058e1ad-e0ae-45fc-8c3e-f40ee84e3568');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-4e08bcad-60f1-45a8-b5ea-4e926a92f126\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4e08bcad-60f1-45a8-b5ea-4e926a92f126')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-4e08bcad-60f1-45a8-b5ea-4e926a92f126 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_39421609-a5b1-4e85-b05f-47e667779402\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_39421609-a5b1-4e85-b05f-47e667779402 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df"}},"metadata":{},"execution_count":11}],"source":["df_train = pd.read_json(\"open_llm/train.jsonl\", lines=True)\n","\n","df_valid = pd.read_json(\"open_llm/valid.jsonl\", lines=True)\n","\n","training_len = len(df_train)\n","\n","df = pd.concat([df_train, df_valid], ignore_index=True)\n","\n","del df_train, df_valid\n","gc.collect()  # Force garbage collection to release memory\n","\n","df"]},{"cell_type":"code","execution_count":null,"id":"WbWJjMpHkVM6","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":7654,"status":"ok","timestamp":1735578846044,"user":{"displayName":"Wojciech Neuman","userId":"02532032841570570568"},"user_tz":-60},"id":"WbWJjMpHkVM6","outputId":"985cf956-a22c-47f7-c3a9-4393e4064ea1"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                              uid  \\\n","0           [urlsf_subset00]-[15]   \n","1           [urlsf_subset00]-[15]   \n","2           [urlsf_subset00]-[83]   \n","3           [urlsf_subset00]-[83]   \n","4           [urlsf_subset00]-[89]   \n","...                           ...   \n","120929  [urlsf_subset06]-[390176]   \n","120930  [urlsf_subset06]-[390305]   \n","120931  [urlsf_subset06]-[390305]   \n","120932  [urlsf_subset06]-[390316]   \n","120933  [urlsf_subset06]-[390316]   \n","\n","                                                     text  label  \n","0       the dangers of illinois as a right to work sta...      0  \n","1       the governor of illinois gov rauner has reques...      1  \n","2       check current weather conditions\\n\\nits going ...      0  \n","3       check current weather conditions its going to ...      1  \n","4       on thursday the president of the united states...      0  \n","...                                                   ...    ...  \n","120929  diego maradona has paid tribute to the late al...      1  \n","120930  tymee holds a guerilla performance\\n\\nby yanch...      0  \n","120931  tymee holds a guerilla performance\\n\\nby yanch...      1  \n","120932  south korea president moon jaein requested a c...      0  \n","120933  president moon jaein of south korea spoke with...      1  \n","\n","[120934 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-ab9c8a82-5d42-4f3f-a77c-07f6602a3b69\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>uid</th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[urlsf_subset00]-[15]</td>\n","      <td>the dangers of illinois as a right to work sta...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[urlsf_subset00]-[15]</td>\n","      <td>the governor of illinois gov rauner has reques...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[urlsf_subset00]-[83]</td>\n","      <td>check current weather conditions\\n\\nits going ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[urlsf_subset00]-[83]</td>\n","      <td>check current weather conditions its going to ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[urlsf_subset00]-[89]</td>\n","      <td>on thursday the president of the united states...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>120929</th>\n","      <td>[urlsf_subset06]-[390176]</td>\n","      <td>diego maradona has paid tribute to the late al...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>120930</th>\n","      <td>[urlsf_subset06]-[390305]</td>\n","      <td>tymee holds a guerilla performance\\n\\nby yanch...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>120931</th>\n","      <td>[urlsf_subset06]-[390305]</td>\n","      <td>tymee holds a guerilla performance\\n\\nby yanch...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>120932</th>\n","      <td>[urlsf_subset06]-[390316]</td>\n","      <td>south korea president moon jaein requested a c...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>120933</th>\n","      <td>[urlsf_subset06]-[390316]</td>\n","      <td>president moon jaein of south korea spoke with...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>120934 rows × 3 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab9c8a82-5d42-4f3f-a77c-07f6602a3b69')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-ab9c8a82-5d42-4f3f-a77c-07f6602a3b69 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-ab9c8a82-5d42-4f3f-a77c-07f6602a3b69');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-c6ff1d38-7b8c-415c-b649-ef3098d271e1\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c6ff1d38-7b8c-415c-b649-ef3098d271e1')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-c6ff1d38-7b8c-415c-b649-ef3098d271e1 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_0d8cfcfe-d66b-4d08-851c-991f1b30bc87\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_0d8cfcfe-d66b-4d08-851c-991f1b30bc87 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df"}},"metadata":{},"execution_count":12}],"source":["def text_process(mess):\n","    \"\"\"\n","    Process text to:\n","    1. Remove punctuation (including all Unicode quotes)\n","    2. Convert text to lowercase\n","    3. Return cleaned text without removing stopwords\n","    \"\"\"\n","    # Remove all punctuation using regex\n","    mess = re.sub(r\"[^\\w\\s]\", \"\", mess)\n","\n","    # Convert the text to lowercase\n","    mess = mess.lower()\n","\n","    # Return the cleaned text\n","    return mess\n","\n","\n","df['text'] = df['text'].apply(text_process)\n","\n","df = df.drop(['extra', 'source'], axis=1)\n","\n","texts = np.array(df.text)\n","labels = np.array(df.label)\n","\n","df"]},{"cell_type":"markdown","id":"90f02642","metadata":{"id":"90f02642"},"source":["## FastText download\n"]},{"cell_type":"code","execution_count":null,"id":"96243dd3","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32332,"status":"ok","timestamp":1735578878368,"user":{"displayName":"Wojciech Neuman","userId":"02532032841570570568"},"user_tz":-60},"id":"96243dd3","outputId":"08f696fe-f5f5-4e61-d0d9-831ab2e09488"},"outputs":[{"output_type":"stream","name":"stdout","text":["CPU times: user 25.2 s, sys: 6.06 s, total: 31.2 s\n","Wall time: 32.5 s\n"]}],"source":["%%time\n","import os\n","import requests\n","from zipfile import ZipFile\n","\n","URL = \"https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip\"\n","FILE = \"fastText\"\n","ZIP_FILE = \"crawl-300d-2M.vec.zip\"\n","\n","if os.path.isdir(FILE):\n","    print(\"fastText exists.\")\n","else:\n","    os.makedirs(FILE, exist_ok=True)\n","    r = requests.get(URL, stream=True)\n","    with open(os.path.join(FILE, ZIP_FILE), 'wb') as f:\n","        for chunk in r.iter_content(chunk_size=8192):\n","            if chunk:\n","                f.write(chunk)\n","\n","    with ZipFile(os.path.join(FILE, ZIP_FILE), 'r') as zip_ref:\n","        zip_ref.extractall(FILE)"]},{"cell_type":"markdown","id":"94779e3d","metadata":{"id":"94779e3d"},"source":["# Data preparation"]},{"cell_type":"markdown","id":"47d72c2f","metadata":{"id":"47d72c2f"},"source":["## Input tokenization and encoding"]},{"cell_type":"code","execution_count":null,"id":"mTulNF4dYpPG","metadata":{"id":"mTulNF4dYpPG"},"outputs":[],"source":["def tokenize(texts):\n","    \"\"\"\n","    Tokenize texts, build a vocabulary, and determine the maximum sentence length.\n","\n","    Args:\n","        texts (List[str]): A list of text data (strings) to be processed.\n","\n","    Returns:\n","        tokenized_texts (List[List[str]]): A list of tokenized sentences, where each text in the input is split into tokens.\n","        word2idx (Dict[str, int]): A dictionary mapping each unique token to a unique integer index. The special token '<unk>' is reserved for unknown tokens and is assigned an index of 0.\n","        max_len (int): The length of the longest tokenized sentence in the input texts.\n","\n","    Process:\n","        1. Initializes a special token '<unk>' in the vocabulary with index 0.\n","        2. Tokenizes each text in the input list using `nltk.word_tokenize`.\n","        3. Adds each unique token to the vocabulary with a unique index.\n","        4. Tracks the length of the longest tokenized sentence.\n","\n","    Example:\n","        texts = [\"Hello world!\", \"How are you?\"]\n","        tokenized_texts, word2idx, max_len = tokenize(texts)\n","\n","        # tokenized_texts = [['Hello', 'world', '!'], ['How', 'are', 'you', '?']]\n","        # word2idx = {'<unk>': 0, 'Hello': 1, 'world': 2, '!': 3, 'How': 4, 'are': 5, 'you': 6, '?': 7}\n","        # max_len = 4\n","    \"\"\"\n","    print(\"Tokenizing texts...\\n\")\n","\n","    max_len = 0\n","    tokenized_texts = []\n","    word2idx = {}\n","\n","    word2idx['<pad>'] = 0\n","    word2idx['<unk>'] = 1\n","\n","    for text in texts:\n","        tokenized_text = nltk.word_tokenize(text)\n","        tokenized_texts.append(tokenized_text)\n","\n","        for token in tokenized_text:\n","            if token not in word2idx:\n","                word2idx[token] = len(word2idx)\n","\n","        if len(tokenized_text) > max_len:\n","            max_len = len(tokenized_text)\n","\n","    return tokenized_texts, word2idx, max_len\n","\n","\n","def encode(tokenized_texts, word2idx, max_len):\n","    \"\"\"\n","    Encode tokenized texts into a numpy array of token indices, with padding.\n","\n","    Args:\n","        tokenized_texts (List[List[str]]): List of tokenized texts.\n","        word2idx (Dict[str, int]): Dictionary mapping each token to its index.\n","        max_len (int): Maximum sentence length (for padding).\n","\n","    Returns:\n","        np.array: A numpy array where each sentence is encoded as a list of token indices, with padding added to sentences shorter than `max_len`.\n","\n","    Process:\n","        1. For each tokenized sentence, pad the sentence with the '<pad>' token if it's shorter than `max_len`.\n","        2. Convert each token to its corresponding index using the `word2idx` dictionary.\n","        3. If a token is not found in `word2idx`, it is replaced with the index for '<unk>' (unknown token).\n","\n","    Example:\n","        tokenized_texts = [['hello', 'world'], ['how', 'are', 'you']]\n","        word2idx = {'<pad>': 0, '<unk>': 1, 'hello': 2, 'world': 3, 'how': 4, 'are': 5, 'you': 6}\n","        max_len = 3\n","\n","        result = encode(tokenized_texts, word2idx, max_len)\n","        # result = np.array([[2, 3, 0], [4, 5, 6]])\n","    \"\"\"\n","    input_idxs = []\n","\n","    for tokenized_text in tokenized_texts:\n","        tokenized_text += ['<pad>'] * (max_len - len(tokenized_text)) # add padding\n","\n","        input_idxs.append([word2idx.get(token, '<unk>') for token in tokenized_text])\n","\n","    return np.array(input_idxs)\n"]},{"cell_type":"markdown","id":"c04d96cb","metadata":{"id":"c04d96cb"},"source":["## Load Pretrained Vectors"]},{"cell_type":"code","execution_count":null,"id":"e6161b7d","metadata":{"id":"e6161b7d"},"outputs":[],"source":["def load_pretrained_vectors(word2idx, fname, embedding_dim=300):\n","    \"\"\"\n","    Load pretrained vectors and create an embedding matrix.\n","\n","    Args:\n","        word2idx (Dict[str, int]): Vocabulary mapping words to indices.\n","        fname (str): Path to the pretrained vector file (e.g., fastText .vec file).\n","        embedding_dim (int): Dimension of the embedding vectors (default: 300).\n","\n","    Returns:\n","        embeddings (np.array): Embedding matrix with shape (N, d), where:\n","            - N is the size of word2idx\n","            - d is the embedding dimension.\n","    \"\"\"\n","\n","    print(\"Loading pretrained vectors...\")\n","\n","    # Initialize random embeddings\n","    embeddings = np.random.uniform(-0.25, 0.25, (len(word2idx), embedding_dim))\n","    embeddings[word2idx.get('<pad>', 0)] = np.zeros((embedding_dim,))  # Handle padding token\n","\n","    with open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore') as fin:\n","        # Check if the first line contains metadata (number of words and dimension)\n","        first_line = fin.readline().strip()\n","        if first_line.replace(' ', '').isdigit():\n","            n, d = map(int, first_line.split())\n","        else:\n","            n, d = None, embedding_dim\n","            fin.seek(0)  # Rewind file if no metadata header\n","\n","        # Ensure dimensions match\n","        assert d == embedding_dim, \\\n","            f\"Embedding dimension mismatch: expected {embedding_dim}, found {d}\"\n","\n","        # Load embeddings\n","        count = 0\n","        for line in tqdm(fin, desc=\"Loading vectors\"):\n","            tokens = line.rstrip().split(' ')\n","            word, vector = tokens[0], tokens[1:]\n","            if word in word2idx:\n","                count += 1\n","                embeddings[word2idx[word]] = np.array(vector, dtype=np.float32)\n","\n","    print(f\"Loaded {count} / {len(word2idx)} pretrained vectors.\")\n","    return embeddings"]},{"cell_type":"markdown","id":"K17Qj_VhdApb","metadata":{"id":"K17Qj_VhdApb"},"source":["## Apply input functions to the dataset"]},{"cell_type":"code","execution_count":null,"id":"a87edf03","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":259592,"status":"ok","timestamp":1735579137957,"user":{"displayName":"Wojciech Neuman","userId":"02532032841570570568"},"user_tz":-60},"id":"a87edf03","outputId":"70c16dca-7303-4d60-dfb4-5f7a29898409"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenizing texts...\n","\n","Loading pretrained vectors...\n"]},{"output_type":"stream","name":"stderr","text":["Loading vectors: 1999995it [00:40, 49771.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Loaded 186989 / 621876 pretrained vectors.\n"]}],"source":["# Tokenize, build vocabulary, encode tokens\n","tokenized_texts, word2idx, max_len = tokenize(texts)\n","input_ids = encode(tokenized_texts, word2idx, max_len)\n","\n","# Path to pretrained embeddings\n","embedding_file = \"fastText/crawl-300d-2M.vec\"\n","\n","# Load pretrained vectors\n","pretrained_embeddings = load_pretrained_vectors(word2idx, embedding_file)\n","embeddings_tensor = torch.tensor(pretrained_embeddings, dtype=torch.float32)"]},{"cell_type":"markdown","id":"d5a68bf7","metadata":{"id":"d5a68bf7"},"source":["## Create PyTorch DataLoader"]},{"cell_type":"code","execution_count":null,"id":"592cceb9","metadata":{"id":"592cceb9"},"outputs":[],"source":["from torch.utils.data import (TensorDataset, DataLoader, RandomSampler,\n","                              SequentialSampler)\n","\n","def data_loader(train_inputs, val_inputs, train_labels, val_labels, batch_size=50):\n","    \"\"\"\n","    Prepare PyTorch DataLoaders for training and validation datasets.\n","\n","    This function takes preprocessed training and validation inputs/labels, converts\n","    them into PyTorch tensors, and creates DataLoader objects. DataLoaders are used\n","    to iterate over batches of data efficiently during training and validation.\n","\n","    Args:\n","        train_inputs (List or np.array): Tokenized and preprocessed training input data.\n","        val_inputs (List or np.array): Tokenized and preprocessed validation input data.\n","        train_labels (List or np.array): Corresponding labels for the training data.\n","        val_labels (List or np.array): Corresponding labels for the validation data.\n","        batch_size (int, optional): Number of samples per batch. Default is 50.\n","\n","    Returns:\n","        Tuple[DataLoader, DataLoader]:\n","            - train_dataloader (DataLoader): DataLoader for the training data.\n","            - val_dataloader (DataLoader): DataLoader for the validation data.\n","\n","    Notes:\n","        - Training data is shuffled to improve model generalization.\n","        - Validation data is not shuffled to ensure consistent evaluation.\n","    \"\"\"\n","    # Convert datasets to PyTorch tensors\n","    tensor_train_inputs = torch.tensor(train_inputs)\n","    tensor_val_inputs = torch.tensor(val_inputs)\n","    tensor_train_labels = torch.tensor(train_labels)\n","    tensor_val_labels = torch.tensor(val_labels)\n","\n","    # Create TensorDataset objects\n","    train_data = TensorDataset(tensor_train_inputs, tensor_train_labels)\n","    val_data = TensorDataset(tensor_val_inputs, tensor_val_labels)\n","\n","    # Create DataLoaders\n","    train_dataloader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n","    val_dataloader = DataLoader(val_data, shuffle=False, batch_size=batch_size)\n","\n","    return train_dataloader, val_dataloader"]},{"cell_type":"code","execution_count":null,"id":"1fddd0b5","metadata":{"id":"1fddd0b5"},"outputs":[],"source":["train_inputs = input_ids[:training_len]\n","train_labels = labels[:training_len]\n","val_inputs = input_ids[training_len:]\n","val_labels = labels[training_len:]\n","\n","# Load data to PyTorch DataLoader\n","train_dataloader, val_dataloader = \\\n","data_loader(train_inputs, val_inputs, train_labels, val_labels, batch_size=50)"]},{"cell_type":"markdown","id":"24451281","metadata":{"id":"24451281"},"source":["## LSTM Model creation"]},{"cell_type":"code","source":["class LSTM_NLP_Bi(nn.Module):\n","    \"\"\"A Bi-directional LSTM Neural Network for Sentence Classification.\"\"\"\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, pretrained_embeddings=None, dropout=0.5):\n","        super(LSTM_NLP_Bi, self).__init__()\n","\n","        # Embedding layer\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        if pretrained_embeddings is not None:\n","            self.embedding.weight = nn.Parameter(pretrained_embeddings)\n","            self.embedding.weight.requires_grad = False  # Freeze embeddings\n","\n","        # Bidirectional LSTM layer\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n","\n","        # Global Max Pooling\n","        self.pooling = nn.AdaptiveMaxPool1d(1)\n","\n","        # Fully connected layer\n","        self.fc = nn.Linear(hidden_dim * 2, output_dim)  # x2 for bi-directional\n","\n","        # Dropout for regularization\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        embedded = self.embedding(x)  # [batch_size, seq_len, embedding_dim]\n","        lstm_out, (hidden, cell) = self.lstm(embedded)  # [batch_size, seq_len, hidden_dim * 2]\n","        lstm_out = lstm_out.permute(0, 2, 1)  # Reshape for pooling: [batch_size, hidden_dim * 2, seq_len]\n","        pooled = self.pooling(lstm_out).squeeze(-1)  # [batch_size, hidden_dim * 2]\n","        dropped = self.dropout(pooled)\n","        output = self.fc(dropped)  # [batch_size, output_dim]\n","        return output"],"metadata":{"id":"mWXNWmOjRvmf"},"id":"mWXNWmOjRvmf","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def initialize_model(vocab_size, embedding_dim, hidden_dim, output_dim,\n","                     pretrained_embeddings=None, dropout=0.5, learning_rate=1e-3):\n","    \"\"\"Initialize the LSTM model, optimizer, and optionally pretrained embeddings.\"\"\"\n","\n","    print(\"Initializing the model...\")\n","    print(f\"Model parameters:\\n\"\n","          f\"\\tDropout rate: {dropout}\\n\"\n","          f\"\\tLearning rate: {learning_rate}\\n\"\n","          f\"\\tEmbeddings: ({embedding_dim}, {vocab_size})\\n\"\n","          f\"\\tHidden dimension: {hidden_dim}\\n\")\n","\n","    # Check and process pretrained embeddings\n","    if pretrained_embeddings is not None:\n","        if isinstance(pretrained_embeddings, np.ndarray):\n","            pretrained_embeddings = torch.tensor(pretrained_embeddings, dtype=torch.float32)\n","        elif not isinstance(pretrained_embeddings, torch.Tensor):\n","            raise ValueError(\"Pretrained embeddings must be a NumPy array or PyTorch tensor.\")\n","        print(f\"\\tPretrained embeddings shape: {pretrained_embeddings.shape}\")\n","    else:\n","        print(\"\\tUsing randomly initialized embeddings.\")\n","\n","    # Initialize the model\n","    lstm_model_bi = LSTM_NLP_Bi(vocab_size, embedding_dim, hidden_dim, output_dim,\n","                                pretrained_embeddings=pretrained_embeddings, dropout=dropout)\n","\n","    lstm_model_bi.to(device)\n","\n","    # Define optimizer and loss function\n","    optimizer = torch.optim.Adam(lstm_model_bi.parameters(), lr=learning_rate)\n","    criterion = nn.CrossEntropyLoss()\n","\n","    return lstm_model_bi, optimizer, criterion\n"],"metadata":{"id":"uqyX0wy_T7M2"},"id":"uqyX0wy_T7M2","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Specify loss function\n","loss_fn = nn.CrossEntropyLoss()\n","\n","def set_seed(seed_value=42):\n","    \"\"\"Set seed for reproducibility.\"\"\"\n","\n","    random.seed(seed_value)\n","    np.random.seed(seed_value)\n","    torch.manual_seed(seed_value)\n","    torch.cuda.manual_seed_all(seed_value)\n","\n","def evaluate(model, val_dataloader):\n","    \"\"\"Evaluate the LSTM model's performance on the validation set.\"\"\"\n","    model.eval()\n","\n","    # Tracking variables\n","    val_loss = []\n","    val_preds = []\n","    val_labels = []\n","\n","    for batch in val_dataloader:\n","        b_input_ids, b_labels = tuple(t.to(device) for t in batch)\n","\n","        with torch.no_grad():\n","            logits = model(b_input_ids)\n","\n","        # Compute loss\n","        loss = loss_fn(logits, b_labels)\n","        val_loss.append(loss.item())\n","\n","        # Get predictions\n","        preds = torch.argmax(logits, dim=1).flatten()\n","        val_preds.extend(preds.cpu().numpy())\n","        val_labels.extend(b_labels.cpu().numpy())\n","\n","    # Compute the F1 score\n","    f1 = f1_score(val_labels, val_preds, average='weighted')  # Use weighted average for multi-class\n","\n","    # Compute the average validation loss\n","    avg_val_loss = np.mean(val_loss)\n","\n","    return avg_val_loss, f1"],"metadata":{"id":"J8OQbUR4UcMi"},"id":"J8OQbUR4UcMi","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(model, optimizer, train_dataloader, val_dataloader=None, epochs=10, early_stopping_patience=5, save_best_model=True):\n","    \"\"\"Train the LSTM model with early stopping, saving the best model based on validation loss.\"\"\"\n","\n","    best_val_loss = float('inf')  # Initialize best validation loss as infinity\n","    epochs_no_improve = 0  # Early stopping counter\n","    scaler = GradScaler()  # For mixed precision training\n","    best_model_state = None  # Variable to store the best model state\n","\n","    print(\"Start training...\\n\")\n","    print(f\"{'Epoch':^7} | {'Train Loss':^12} | {'Train F1':^9} | {'Val Loss':^10} | {'Val F1':^9} | {'Elapsed':^9}\")\n","    print(\"-\" * 72)\n","\n","    for epoch_i in range(epochs):\n","        t0_epoch = time.time()\n","        total_loss = 0\n","        train_preds = []\n","        train_labels = []\n","\n","        model.train()\n","\n","        for step, batch in enumerate(train_dataloader):\n","            b_input_ids, b_labels = tuple(t.to(device) for t in batch)\n","\n","            optimizer.zero_grad()\n","\n","            # Mixed precision forward pass\n","            with autocast():\n","                logits = model(b_input_ids)\n","                loss = loss_fn(logits, b_labels)\n","\n","            # Backward pass and optimization\n","            scaler.scale(loss).backward()\n","            scaler.step(optimizer)\n","            scaler.update()\n","\n","            total_loss += loss.item()\n","\n","            # Collect training predictions and labels for F1 score\n","            preds = torch.argmax(logits, dim=1).flatten()\n","            train_preds.extend(preds.cpu().numpy())\n","            train_labels.extend(b_labels.cpu().numpy())\n","\n","        avg_train_loss = total_loss / len(train_dataloader)\n","        train_f1 = f1_score(train_labels, train_preds, average='weighted')\n","\n","        if val_dataloader is not None:\n","            val_loss, val_f1 = evaluate(model, val_dataloader)\n","\n","            # Save the model with the lowest validation loss\n","            if val_loss < best_val_loss:\n","                best_val_loss = val_loss\n","                epochs_no_improve = 0\n","\n","                # Save the best model state based on the validation loss\n","                if save_best_model:\n","                    best_model_state = model.state_dict()\n","\n","            else:\n","                epochs_no_improve += 1\n","\n","            if epochs_no_improve >= early_stopping_patience:\n","                print(f\"\\nStopping early at epoch {epoch_i + 1}.\")\n","                break\n","\n","            time_elapsed = time.time() - t0_epoch\n","            print(f\"{epoch_i + 1:^7} | {avg_train_loss:^12.4f} | {train_f1:^9.4f} | {val_loss:^10.4f} | {val_f1:^9.4f} | {time_elapsed:^9.2f}\")\n","        else:\n","            time_elapsed = time.time() - t0_epoch\n","            print(f\"{epoch_i + 1:^7} | {avg_train_loss:^12.4f} | {train_f1:^9.4f} | {'N/A':^10} | {'N/A':^9} | {time_elapsed:^9.2f}\")\n","\n","    print(\"\\nTraining complete!\")\n","    print(f\"Best validation loss: {best_val_loss:.3f}\")\n"],"metadata":{"id":"IC75cjDvUurI"},"id":"IC75cjDvUurI","execution_count":null,"outputs":[]},{"cell_type":"code","source":["set_seed(42)\n","\n","# Initialize hyperparameters\n","vocab_size = len(word2idx)\n","embedding_dim = 300  # Embedding dimension\n","hidden_dim = 256  # LSTM hidden units\n","output_dim = 2\n","dropout = 0.7\n","learning_rate = 1e-3\n","save_best_model = True\n","\n","epochs = 25\n","early_stopping_patience = 5\n","\n","best_model_state = None\n","\n","# Initialize model, optimizer and criterion\n","lstm_model, optimizer, criterion = initialize_model(\n","    vocab_size=vocab_size,\n","    embedding_dim=embedding_dim,\n","    hidden_dim=hidden_dim,\n","    output_dim=output_dim,\n","    pretrained_embeddings=embeddings_tensor,\n","    dropout=dropout,\n","    learning_rate=learning_rate\n",")\n","\n","# Train the model\n","train(\n","    model=lstm_model,\n","    optimizer=optimizer,\n","    train_dataloader=train_dataloader,\n","    val_dataloader=val_dataloader,\n","    epochs=epochs,\n","    early_stopping_patience=early_stopping_patience,\n","    save_best_model=save_best_model\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l6XjYIbHU1A6","executionInfo":{"status":"ok","timestamp":1735586191395,"user_tz":-60,"elapsed":2727080,"user":{"displayName":"Wojciech Neuman","userId":"02532032841570570568"}},"outputId":"10ebf8a6-464e-49c5-9d11-e6e491c8c876"},"id":"l6XjYIbHU1A6","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Initializing the model...\n","Model parameters:\n","\tDropout rate: 0.7\n","\tLearning rate: 0.001\n","\tEmbeddings: (300, 621876)\n","\tHidden dimension: 256\n","\n","\tPretrained embeddings shape: torch.Size([621876, 300])\n","Start training...\n","\n"," Epoch  |  Train Loss  | Train F1  |  Val Loss  |  Val F1   |  Elapsed \n","------------------------------------------------------------------------\n","   1    |    0.3820    |  0.8200   |   0.2402   |  0.9031   |  247.57  \n","   2    |    0.2278    |  0.9067   |   0.2150   |  0.9131   |  247.61  \n","   3    |    0.1865    |  0.9253   |   0.1796   |  0.9267   |  247.69  \n","   4    |    0.1571    |  0.9381   |   0.1645   |  0.9352   |  247.76  \n","   5    |    0.1380    |  0.9455   |   0.1632   |  0.9344   |  247.70  \n","   6    |    0.1176    |  0.9540   |   0.1567   |  0.9408   |  247.87  \n","   7    |    0.1009    |  0.9612   |   0.1842   |  0.9314   |  247.81  \n","   8    |    0.0917    |  0.9647   |   0.1977   |  0.9337   |  247.75  \n","   9    |    0.0757    |  0.9712   |   0.1697   |  0.9378   |  247.93  \n","  10    |    0.0627    |  0.9762   |   0.1886   |  0.9392   |  247.75  \n","\n","Stopping early at epoch 11.\n","\n","Training complete!\n","Best validation loss: 0.157\n"]}]},{"cell_type":"markdown","source":["## Save the model and essential information"],"metadata":{"id":"zmrudb0EotSU"},"id":"zmrudb0EotSU"},{"cell_type":"code","source":["# Save the embeddings tensor (pretrained word embeddings)\n","embeddings_tensor_path = os.path.join(drive_path, 'embeddings_tensor.pth')\n","torch.save(embeddings_tensor, embeddings_tensor_path)\n","\n","# Save the word2idx dictionary (tokenizer mapping)\n","word2idx_path = os.path.join(drive_path, 'word2idx.pkl')\n","with open(word2idx_path, 'wb') as file:\n","    pickle.dump(word2idx, file)\n","\n","# Save max_len (maximum length of sequences)\n","max_len_path = os.path.join(drive_path, 'max_len.pkl')\n","with open(max_len_path, 'wb') as file:\n","    pickle.dump(max_len, file)\n","\n","# Save the best model with the highest F1 score\n","best_model_path = os.path.join(drive_path, 'best_lstm_model.pth')\n","if save_best_model and best_model_state is not None:\n","    torch.save(best_model_state, best_model_path)\n","else:\n","    torch.save(lstm_model.state_dict(), best_model_path)\n","\n","# Save the model parameters as a JSON file\n","model_params = {\n","    'vocab_size': vocab_size,\n","    'embedding_dim': embedding_dim,\n","    'hidden_dim': hidden_dim,\n","    'output_dim': output_dim,\n","    'dropout': dropout,\n","}\n","params_save_path = os.path.join(drive_path, 'model_params.json')\n","with open(params_save_path, 'w') as f:\n","    json.dump(model_params, f, indent=4)\n","\n","print(f\"Model parameters saved to: {params_save_path}\")\n","\n","# Output paths to confirm the saving\n","print(f\"Embeddings tensor saved to: {embeddings_tensor_path}\")\n","print(f\"word2idx saved to: {word2idx_path}\")\n","print(f\"max_len saved to: {max_len_path}\")\n","print(f\"Best model saved to: {best_model_path}\")\n","print(f\"Model parameters saved to: {params_save_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hVhaecm3HZi6","executionInfo":{"status":"ok","timestamp":1735583106967,"user_tz":-60,"elapsed":8571,"user":{"displayName":"Wojciech Neuman","userId":"02532032841570570568"}},"outputId":"2f5602b8-d1ef-4fcf-dee7-45344982a7cc"},"id":"hVhaecm3HZi6","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model parameters saved to: /content/drive/MyDrive/Thesis/Models/LSTM/model_params.json\n","Embeddings tensor saved to: /content/drive/MyDrive/Thesis/Models/LSTM/embeddings_tensor.pth\n","word2idx saved to: /content/drive/MyDrive/Thesis/Models/LSTM/word2idx.pkl\n","max_len saved to: /content/drive/MyDrive/Thesis/Models/LSTM/max_len.pkl\n","Best model saved to: /content/drive/MyDrive/Thesis/Models/LSTM/best_lstm_model.pth\n","Model parameters saved to: /content/drive/MyDrive/Thesis/Models/LSTM/model_params.json\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1BaGd8kclYPWnHNDn4c7aQB1_-bAiCX_0","timestamp":1737635169547},{"file_id":"15pObc3FDGA4vi1l8tSxx58ygbSD6XcTg","timestamp":1735577660966},{"file_id":"1iLCEvxGwc3ICHGDMih9cJZ0gFuqPMkGS","timestamp":1735475638795},{"file_id":"1YTX5OpB2mQK5THOSogqDA13nW2JCTa8v","timestamp":1735294500861},{"file_id":"1KONv0rDL55qXFbUPM6_SDhBYknAIbNUk","timestamp":1734915962197}],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}