{"cells":[{"cell_type":"markdown","id":"6e08bc6c","metadata":{"id":"6e08bc6c"},"source":["# CNN with FastText word-embeddings Training"]},{"cell_type":"markdown","id":"0e1df9cd","metadata":{"id":"0e1df9cd"},"source":["## Dataset loading"]},{"cell_type":"markdown","id":"2lJUIgCsgs83","metadata":{"id":"2lJUIgCsgs83"},"source":["5k Sample set:\n","\n","train\n","https://drive.google.com/file/d/19t64Y_q5X9_2XkcePFCloFeMGj-zziDc/view?usp=drive_link\n","\n","test\n","https://drive.google.com/file/d/1GgUb75IjJYkFygqWHZWiTiSZ9htWXsG-/view?usp=sharing\n","\n","valid\n","https://drive.google.com/file/d/1Rq3OpD0ZfQ23zrJntAb-5X9p3GeQCVBy/view?usp=drive_link\n","\n","\n","All data set:\n","\n","train\n","https://drive.google.com/file/d/1cA6QNMauKvZr4W62UZS9ysgrGEbURg7Y/view?usp=drive_link\n","\n","test\n","https://drive.google.com/file/d/1hja3qBUB8BvTbhtpuaPHDkuvKOuOda7M/view?usp=drive_link\n","\n","valid\n","https://drive.google.com/file/d/1f6p93RDkV9AeaWcprzKMGKjtgQr0opU0/view?usp=sharing\n","\n","New all data set:\n","\n","train\n","https://drive.google.com/file/d/1mNUOXt3ZiERCH401TkSGXx7-LpbmbMaK/view?usp=sharing\n","\n","test\n","https://drive.google.com/file/d/16p0td9GgJRb9AP8i4HlX-xZGI2u849uA/view?usp=sharing\n","\n","valid\n","https://drive.google.com/file/d/1FhT3m_ApKzX615JzshB5-d-j6S91-6oz/view?usp=sharing"]},{"cell_type":"code","execution_count":null,"id":"KgvBMguefVO0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24711,"status":"ok","timestamp":1735599384283,"user":{"displayName":"Wojciech Neuman","userId":"02532032841570570568"},"user_tz":-60},"id":"KgvBMguefVO0","outputId":"e32f528a-190b-44f7-849f-737e05f25062"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From (original): https://drive.google.com/uc?id=1mNUOXt3ZiERCH401TkSGXx7-LpbmbMaK\n","From (redirected): https://drive.google.com/uc?id=1mNUOXt3ZiERCH401TkSGXx7-LpbmbMaK&confirm=t&uuid=9ff659f8-9bb3-48d2-9d69-5dc3097cad2c\n","To: /content/train.jsonl\n","100% 292M/292M [00:04<00:00, 70.3MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=1FhT3m_ApKzX615JzshB5-d-j6S91-6oz\n","To: /content/valid.jsonl\n","100% 55.1M/55.1M [00:00<00:00, 60.4MB/s]\n","Downloading...\n","From: https://drive.google.com/uc?id=16p0td9GgJRb9AP8i4HlX-xZGI2u849uA\n","To: /content/test.jsonl\n","100% 39.1M/39.1M [00:00<00:00, 57.3MB/s]\n"]}],"source":["# All training dataset\n","! gdown 1mNUOXt3ZiERCH401TkSGXx7-LpbmbMaK # new all train\n","! gdown 1FhT3m_ApKzX615JzshB5-d-j6S91-6oz # new all valid\n","! gdown 16p0td9GgJRb9AP8i4HlX-xZGI2u849uA # new all test\n","\n","\n","! mkdir open_llm\n","! mv train.jsonl valid.jsonl test.jsonl open_llm/"]},{"cell_type":"code","execution_count":null,"id":"qapaJvjGuvOT","metadata":{"id":"qapaJvjGuvOT"},"outputs":[],"source":["! mkdir models # used for saving models"]},{"cell_type":"markdown","source":["## Library Installation"],"metadata":{"id":"JXJLFM2Dmzk1"},"id":"JXJLFM2Dmzk1"},{"cell_type":"code","execution_count":null,"id":"14490533","metadata":{"id":"14490533"},"outputs":[],"source":["# Standard Libraries\n","import os\n","import re\n","import gc\n","import json\n","import pickle\n","import requests\n","from zipfile import ZipFile\n","\n","# Data Science & Machine Learning Libraries\n","import numpy as np\n","import pandas as pd\n","from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, classification_report, confusion_matrix\n","\n","# Natural Language Processing Libraries\n","import nltk\n","from nltk.tokenize import word_tokenize\n","\n","# PyTorch Libraries\n","import torch\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from torch.cuda.amp import autocast, GradScaler\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# Visualization Libraries\n","import matplotlib.pyplot as plt\n","\n","# Progress Bar Libraries\n","from tqdm import tqdm, tqdm_notebook\n"]},{"cell_type":"code","source":["import warnings\n","warnings.filterwarnings(\"ignore\", category=FutureWarning)"],"metadata":{"id":"z0ulPjV-yZDl"},"id":"z0ulPjV-yZDl","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"SBpgNYtvkf57","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1735599390550,"user":{"displayName":"Wojciech Neuman","userId":"02532032841570570568"},"user_tz":-60},"id":"SBpgNYtvkf57","outputId":"40918516-b689-4423-db3a-a19d0d58e7a9"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":5}],"source":["from nltk.corpus import stopwords\n","\n","nltk.download('stopwords')\n","\n","STOPWORDS = set(stopwords.words('english'))\n","\n","nltk.download('punkt_tab')"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Path to save files in Google Drive\n","drive_path = '/content/drive/MyDrive/Thesis/Models/CNN/'\n","\n","# Ensure the folder exists\n","os.makedirs(drive_path, exist_ok=True)"],"metadata":{"id":"3ftQkIbVsO8N","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735599413116,"user_tz":-60,"elapsed":22568,"user":{"displayName":"Wojciech Neuman","userId":"02532032841570570568"}},"outputId":"708ed30d-17f7-474c-f061-bb1a04dc5d23"},"id":"3ftQkIbVsO8N","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["## Choose runtime environment"],"metadata":{"id":"jveRSuOBxPXy"},"id":"jveRSuOBxPXy"},{"cell_type":"code","source":["# Check if CUDA (GPU) is available\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    gpu_name = torch.cuda.get_device_name(0)\n","    gpu_capability = torch.cuda.get_device_properties(0).major, torch.cuda.get_device_properties(0).minor\n","    print(f\"Using GPU: {gpu_name}\")\n","    print(f\"Compute Capability: {gpu_capability}\")\n","    print(f\"CUDA Device Count: {torch.cuda.device_count()}\")\n","    print(f\"Memory Allocated: {torch.cuda.memory_allocated(0)} bytes\")\n","    print(f\"Memory Reserved: {torch.cuda.memory_reserved(0)} bytes\")\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"Using CPU\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oPxbgMFWxPq7","executionInfo":{"status":"ok","timestamp":1735599413116,"user_tz":-60,"elapsed":17,"user":{"displayName":"Wojciech Neuman","userId":"02532032841570570568"}},"outputId":"3ce542cd-edba-49df-914c-5bc342b8e1e4"},"id":"oPxbgMFWxPq7","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using GPU: Tesla T4\n","Compute Capability: (7, 5)\n","CUDA Device Count: 1\n","Memory Allocated: 0 bytes\n","Memory Reserved: 0 bytes\n"]}]},{"cell_type":"markdown","id":"94226d9d","metadata":{"id":"94226d9d"},"source":["## Data preparation"]},{"cell_type":"code","execution_count":null,"id":"1547a43f","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"elapsed":3933,"status":"ok","timestamp":1735599417043,"user":{"displayName":"Wojciech Neuman","userId":"02532032841570570568"},"user_tz":-60},"id":"1547a43f","outputId":"4672a50c-aab1-4391-96d2-ff9004a17686"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                              uid  \\\n","0           [urlsf_subset00]-[15]   \n","1           [urlsf_subset00]-[15]   \n","2           [urlsf_subset00]-[83]   \n","3           [urlsf_subset00]-[83]   \n","4           [urlsf_subset00]-[89]   \n","...                           ...   \n","120929  [urlsf_subset06]-[390176]   \n","120930  [urlsf_subset06]-[390305]   \n","120931  [urlsf_subset06]-[390305]   \n","120932  [urlsf_subset06]-[390316]   \n","120933  [urlsf_subset06]-[390316]   \n","\n","                                                     text  \\\n","0       The dangers of Illinois as a ‘right to work’ s...   \n","1       The governor of Illinois, Gov. Rauner, has req...   \n","2       Check current weather conditions\\n\\nIt’s going...   \n","3       Check current weather conditions It’s going to...   \n","4       On Thursday, the president of the United State...   \n","...                                                   ...   \n","120929  Diego Maradona has paid tribute to the late Al...   \n","120930  Tymee Holds A Guerilla Performance\\n\\n[by Yanc...   \n","120931  Tymee Holds A Guerilla Performance\\n\\n[by Yanc...   \n","120932  South Korea President Moon Jae-in requested a ...   \n","120933  President Moon Jae-in of South Korea spoke wit...   \n","\n","                                               extra   source  label  \n","0       {'source': 'openweb', 'variant': 'original'}  openweb      0  \n","1       {'source': 'chatgpt', 'variant': 'original'}  chatgpt      1  \n","2       {'source': 'openweb', 'variant': 'original'}  openweb      0  \n","3         {'variant': 'original', 'source': 'llama'}    llama      1  \n","4       {'source': 'openweb', 'variant': 'original'}  openweb      0  \n","...                                              ...      ...    ...  \n","120929  {'source': 'chatgpt', 'variant': 'original'}  chatgpt      1  \n","120930  {'source': 'openweb', 'variant': 'original'}  openweb      0  \n","120931    {'variant': 'original', 'source': 'llama'}    llama      1  \n","120932  {'source': 'openweb', 'variant': 'original'}  openweb      0  \n","120933  {'source': 'chatgpt', 'variant': 'original'}  chatgpt      1  \n","\n","[120934 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-52444858-8684-4174-918e-6a2bd2797eba\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>uid</th>\n","      <th>text</th>\n","      <th>extra</th>\n","      <th>source</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[urlsf_subset00]-[15]</td>\n","      <td>The dangers of Illinois as a ‘right to work’ s...</td>\n","      <td>{'source': 'openweb', 'variant': 'original'}</td>\n","      <td>openweb</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[urlsf_subset00]-[15]</td>\n","      <td>The governor of Illinois, Gov. Rauner, has req...</td>\n","      <td>{'source': 'chatgpt', 'variant': 'original'}</td>\n","      <td>chatgpt</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[urlsf_subset00]-[83]</td>\n","      <td>Check current weather conditions\\n\\nIt’s going...</td>\n","      <td>{'source': 'openweb', 'variant': 'original'}</td>\n","      <td>openweb</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[urlsf_subset00]-[83]</td>\n","      <td>Check current weather conditions It’s going to...</td>\n","      <td>{'variant': 'original', 'source': 'llama'}</td>\n","      <td>llama</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[urlsf_subset00]-[89]</td>\n","      <td>On Thursday, the president of the United State...</td>\n","      <td>{'source': 'openweb', 'variant': 'original'}</td>\n","      <td>openweb</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>120929</th>\n","      <td>[urlsf_subset06]-[390176]</td>\n","      <td>Diego Maradona has paid tribute to the late Al...</td>\n","      <td>{'source': 'chatgpt', 'variant': 'original'}</td>\n","      <td>chatgpt</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>120930</th>\n","      <td>[urlsf_subset06]-[390305]</td>\n","      <td>Tymee Holds A Guerilla Performance\\n\\n[by Yanc...</td>\n","      <td>{'source': 'openweb', 'variant': 'original'}</td>\n","      <td>openweb</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>120931</th>\n","      <td>[urlsf_subset06]-[390305]</td>\n","      <td>Tymee Holds A Guerilla Performance\\n\\n[by Yanc...</td>\n","      <td>{'variant': 'original', 'source': 'llama'}</td>\n","      <td>llama</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>120932</th>\n","      <td>[urlsf_subset06]-[390316]</td>\n","      <td>South Korea President Moon Jae-in requested a ...</td>\n","      <td>{'source': 'openweb', 'variant': 'original'}</td>\n","      <td>openweb</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>120933</th>\n","      <td>[urlsf_subset06]-[390316]</td>\n","      <td>President Moon Jae-in of South Korea spoke wit...</td>\n","      <td>{'source': 'chatgpt', 'variant': 'original'}</td>\n","      <td>chatgpt</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>120934 rows × 5 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52444858-8684-4174-918e-6a2bd2797eba')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-52444858-8684-4174-918e-6a2bd2797eba button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-52444858-8684-4174-918e-6a2bd2797eba');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-892cef96-be4e-4b9b-8695-c81ab4586fdc\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-892cef96-be4e-4b9b-8695-c81ab4586fdc')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-892cef96-be4e-4b9b-8695-c81ab4586fdc button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_05eff8b7-6454-4412-add4-c2eda703b60e\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_05eff8b7-6454-4412-add4-c2eda703b60e button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df"}},"metadata":{},"execution_count":8}],"source":["df_train = pd.read_json(\"open_llm/train.jsonl\", lines=True)\n","\n","df_valid = pd.read_json(\"open_llm/valid.jsonl\", lines=True)\n","\n","training_len = len(df_train)\n","\n","df = pd.concat([df_train, df_valid], ignore_index=True)\n","\n","del df_train, df_valid\n","gc.collect()  # Force garbage collection to release memory\n","\n","df"]},{"cell_type":"code","execution_count":null,"id":"WbWJjMpHkVM6","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"elapsed":7343,"status":"ok","timestamp":1735599424379,"user":{"displayName":"Wojciech Neuman","userId":"02532032841570570568"},"user_tz":-60},"id":"WbWJjMpHkVM6","outputId":"459b46c2-702c-4fbc-8354-e25a4480024e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                              uid  \\\n","0           [urlsf_subset00]-[15]   \n","1           [urlsf_subset00]-[15]   \n","2           [urlsf_subset00]-[83]   \n","3           [urlsf_subset00]-[83]   \n","4           [urlsf_subset00]-[89]   \n","...                           ...   \n","120929  [urlsf_subset06]-[390176]   \n","120930  [urlsf_subset06]-[390305]   \n","120931  [urlsf_subset06]-[390305]   \n","120932  [urlsf_subset06]-[390316]   \n","120933  [urlsf_subset06]-[390316]   \n","\n","                                                     text  label  \n","0       the dangers of illinois as a right to work sta...      0  \n","1       the governor of illinois gov rauner has reques...      1  \n","2       check current weather conditions\\n\\nits going ...      0  \n","3       check current weather conditions its going to ...      1  \n","4       on thursday the president of the united states...      0  \n","...                                                   ...    ...  \n","120929  diego maradona has paid tribute to the late al...      1  \n","120930  tymee holds a guerilla performance\\n\\nby yanch...      0  \n","120931  tymee holds a guerilla performance\\n\\nby yanch...      1  \n","120932  south korea president moon jaein requested a c...      0  \n","120933  president moon jaein of south korea spoke with...      1  \n","\n","[120934 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-0c4eac88-cbed-4360-a0ea-9dea8b19ba0e\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>uid</th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[urlsf_subset00]-[15]</td>\n","      <td>the dangers of illinois as a right to work sta...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[urlsf_subset00]-[15]</td>\n","      <td>the governor of illinois gov rauner has reques...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[urlsf_subset00]-[83]</td>\n","      <td>check current weather conditions\\n\\nits going ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[urlsf_subset00]-[83]</td>\n","      <td>check current weather conditions its going to ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[urlsf_subset00]-[89]</td>\n","      <td>on thursday the president of the united states...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>120929</th>\n","      <td>[urlsf_subset06]-[390176]</td>\n","      <td>diego maradona has paid tribute to the late al...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>120930</th>\n","      <td>[urlsf_subset06]-[390305]</td>\n","      <td>tymee holds a guerilla performance\\n\\nby yanch...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>120931</th>\n","      <td>[urlsf_subset06]-[390305]</td>\n","      <td>tymee holds a guerilla performance\\n\\nby yanch...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>120932</th>\n","      <td>[urlsf_subset06]-[390316]</td>\n","      <td>south korea president moon jaein requested a c...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>120933</th>\n","      <td>[urlsf_subset06]-[390316]</td>\n","      <td>president moon jaein of south korea spoke with...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>120934 rows × 3 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0c4eac88-cbed-4360-a0ea-9dea8b19ba0e')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-0c4eac88-cbed-4360-a0ea-9dea8b19ba0e button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-0c4eac88-cbed-4360-a0ea-9dea8b19ba0e');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-cdeae705-f216-4cdf-8b8a-1efde7ba5e2f\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cdeae705-f216-4cdf-8b8a-1efde7ba5e2f')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-cdeae705-f216-4cdf-8b8a-1efde7ba5e2f button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_2f8bf9f6-bbf3-45d1-9254-01c5ba0048f5\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_2f8bf9f6-bbf3-45d1-9254-01c5ba0048f5 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df"}},"metadata":{},"execution_count":9}],"source":["def text_process(mess):\n","    \"\"\"\n","    Process text to:\n","    1. Remove punctuation (including all Unicode quotes)\n","    2. Convert text to lowercase\n","    3. Return cleaned text without removing stopwords\n","    \"\"\"\n","    # Remove all punctuation using regex\n","    mess = re.sub(r\"[^\\w\\s]\", \"\", mess)\n","\n","    # Convert the text to lowercase\n","    mess = mess.lower()\n","\n","    # Return the cleaned text\n","    return mess\n","\n","\n","df['text'] = df['text'].apply(text_process)\n","\n","df = df.drop(['extra', 'source'], axis=1)\n","\n","texts = np.array(df.text)\n","labels = np.array(df.label)\n","\n","df"]},{"cell_type":"markdown","id":"90f02642","metadata":{"id":"90f02642"},"source":["## FastText download\n"]},{"cell_type":"code","execution_count":null,"id":"96243dd3","metadata":{"id":"96243dd3"},"outputs":[],"source":["URL = \"https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip\"\n","FILE = \"fastText\"\n","ZIP_FILE = \"crawl-300d-2M.vec.zip\"\n","\n","if os.path.isdir(FILE):\n","    print(\"fastText exists.\")\n","else:\n","    os.makedirs(FILE, exist_ok=True)\n","    r = requests.get(URL, stream=True)\n","    with open(os.path.join(FILE, ZIP_FILE), 'wb') as f:\n","        for chunk in r.iter_content(chunk_size=8192):\n","            if chunk:\n","                f.write(chunk)\n","\n","    with ZipFile(os.path.join(FILE, ZIP_FILE), 'r') as zip_ref:\n","        zip_ref.extractall(FILE)"]},{"cell_type":"markdown","id":"94779e3d","metadata":{"id":"94779e3d"},"source":["# Data preparation"]},{"cell_type":"markdown","id":"47d72c2f","metadata":{"id":"47d72c2f"},"source":["## Input tokenization and encoding"]},{"cell_type":"code","execution_count":null,"id":"mTulNF4dYpPG","metadata":{"id":"mTulNF4dYpPG"},"outputs":[],"source":["def tokenize(texts):\n","    \"\"\"\n","    Tokenize texts, build a vocabulary, and determine the maximum sentence length.\n","\n","    Args:\n","        texts (List[str]): A list of text data (strings) to be processed.\n","\n","    Returns:\n","        tokenized_texts (List[List[str]]): A list of tokenized sentences, where each text in the input is split into tokens.\n","        word2idx (Dict[str, int]): A dictionary mapping each unique token to a unique integer index. The special token '<unk>' is reserved for unknown tokens and is assigned an index of 0.\n","        max_len (int): The length of the longest tokenized sentence in the input texts.\n","\n","    Process:\n","        1. Initializes a special token '<unk>' in the vocabulary with index 0.\n","        2. Tokenizes each text in the input list using `nltk.word_tokenize`.\n","        3. Adds each unique token to the vocabulary with a unique index.\n","        4. Tracks the length of the longest tokenized sentence.\n","\n","    Example:\n","        texts = [\"Hello world!\", \"How are you?\"]\n","        tokenized_texts, word2idx, max_len = tokenize(texts)\n","\n","        # tokenized_texts = [['Hello', 'world', '!'], ['How', 'are', 'you', '?']]\n","        # word2idx = {'<unk>': 0, 'Hello': 1, 'world': 2, '!': 3, 'How': 4, 'are': 5, 'you': 6, '?': 7}\n","        # max_len = 4\n","    \"\"\"\n","    print(\"Tokenizing texts...\\n\")\n","\n","    max_len = 0\n","    tokenized_texts = []\n","    word2idx = {}\n","\n","    word2idx['<pad>'] = 0\n","    word2idx['<unk>'] = 1\n","\n","    for text in texts:\n","        tokenized_text = nltk.word_tokenize(text)\n","        tokenized_texts.append(tokenized_text)\n","\n","        for token in tokenized_text:\n","            if token not in word2idx:\n","                word2idx[token] = len(word2idx)\n","\n","        if len(tokenized_text) > max_len:\n","            max_len = len(tokenized_text)\n","\n","    return tokenized_texts, word2idx, max_len\n","\n","\n","def encode(tokenized_texts, word2idx, max_len):\n","    \"\"\"\n","    Encode tokenized texts into a numpy array of token indices, with padding.\n","\n","    Args:\n","        tokenized_texts (List[List[str]]): List of tokenized texts.\n","        word2idx (Dict[str, int]): Dictionary mapping each token to its index.\n","        max_len (int): Maximum sentence length (for padding).\n","\n","    Returns:\n","        np.array: A numpy array where each sentence is encoded as a list of token indices, with padding added to sentences shorter than `max_len`.\n","\n","    Process:\n","        1. For each tokenized sentence, pad the sentence with the '<pad>' token if it's shorter than `max_len`.\n","        2. Convert each token to its corresponding index using the `word2idx` dictionary.\n","        3. If a token is not found in `word2idx`, it is replaced with the index for '<unk>' (unknown token).\n","\n","    Example:\n","        tokenized_texts = [['hello', 'world'], ['how', 'are', 'you']]\n","        word2idx = {'<pad>': 0, '<unk>': 1, 'hello': 2, 'world': 3, 'how': 4, 'are': 5, 'you': 6}\n","        max_len = 3\n","\n","        result = encode(tokenized_texts, word2idx, max_len)\n","        # result = np.array([[2, 3, 0], [4, 5, 6]])\n","    \"\"\"\n","    input_idxs = []\n","\n","    for tokenized_text in tokenized_texts:\n","        tokenized_text += ['<pad>'] * (max_len - len(tokenized_text)) # add padding\n","\n","        input_idxs.append([word2idx.get(token, '<unk>') for token in tokenized_text])\n","\n","    return np.array(input_idxs)\n"]},{"cell_type":"markdown","id":"c04d96cb","metadata":{"id":"c04d96cb"},"source":["## Load Pretrained Vectors"]},{"cell_type":"code","execution_count":null,"id":"e6161b7d","metadata":{"id":"e6161b7d"},"outputs":[],"source":["def load_pretrained_vectors(word2idx, fname, embedding_dim=300):\n","    \"\"\"\n","    Load pretrained vectors and create an embedding matrix.\n","\n","    Args:\n","        word2idx (Dict[str, int]): Vocabulary mapping words to indices.\n","        fname (str): Path to the pretrained vector file (e.g., fastText .vec file).\n","        embedding_dim (int): Dimension of the embedding vectors (default: 300).\n","\n","    Returns:\n","        embeddings (np.array): Embedding matrix with shape (N, d), where:\n","            - N is the size of word2idx\n","            - d is the embedding dimension.\n","    \"\"\"\n","\n","    print(\"Loading pretrained vectors...\")\n","\n","    # Initialize random embeddings\n","    embeddings = np.random.uniform(-0.25, 0.25, (len(word2idx), embedding_dim))\n","    embeddings[word2idx.get('<pad>', 0)] = np.zeros((embedding_dim,))  # Handle padding token\n","\n","    with open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore') as fin:\n","        # Check if the first line contains metadata (number of words and dimension)\n","        first_line = fin.readline().strip()\n","        if first_line.replace(' ', '').isdigit():\n","            n, d = map(int, first_line.split())\n","        else:\n","            n, d = None, embedding_dim\n","            fin.seek(0)  # Rewind file if no metadata header\n","\n","        # Ensure dimensions match\n","        assert d == embedding_dim, \\\n","            f\"Embedding dimension mismatch: expected {embedding_dim}, found {d}\"\n","\n","        # Load embeddings\n","        count = 0\n","        for line in tqdm(fin, desc=\"Loading vectors\"):\n","            tokens = line.rstrip().split(' ')\n","            word, vector = tokens[0], tokens[1:]\n","            if word in word2idx:\n","                count += 1\n","                embeddings[word2idx[word]] = np.array(vector, dtype=np.float32)\n","\n","    print(f\"Loaded {count} / {len(word2idx)} pretrained vectors.\")\n","    return embeddings"]},{"cell_type":"markdown","id":"K17Qj_VhdApb","metadata":{"id":"K17Qj_VhdApb"},"source":["## Apply input functions to the dataset"]},{"cell_type":"code","execution_count":null,"id":"a87edf03","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":278491,"status":"ok","timestamp":1735599792734,"user":{"displayName":"Wojciech Neuman","userId":"02532032841570570568"},"user_tz":-60},"id":"a87edf03","outputId":"47c74f4d-6b95-4e22-b735-0addbb2d34ef"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tokenizing texts...\n","\n","Loading pretrained vectors...\n"]},{"output_type":"stream","name":"stderr","text":["Loading vectors: 1999995it [00:43, 45509.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Loaded 186989 / 621876 pretrained vectors.\n"]}],"source":["# Tokenize, build vocabulary, encode tokens\n","tokenized_texts, word2idx, max_len = tokenize(texts)\n","input_ids = encode(tokenized_texts, word2idx, max_len)\n","\n","# Path to pretrained embeddings\n","embedding_file = \"fastText/crawl-300d-2M.vec\"\n","\n","# Load pretrained vectors\n","pretrained_embeddings = load_pretrained_vectors(word2idx, embedding_file)\n","embeddings_tensor = torch.tensor(pretrained_embeddings, dtype=torch.float32)"]},{"cell_type":"markdown","id":"d5a68bf7","metadata":{"id":"d5a68bf7"},"source":["## Create PyTorch DataLoader"]},{"cell_type":"code","execution_count":null,"id":"592cceb9","metadata":{"id":"592cceb9"},"outputs":[],"source":["def data_loader(train_inputs, val_inputs, train_labels, val_labels, batch_size=50):\n","    \"\"\"\n","    Prepare PyTorch DataLoaders for training and validation datasets.\n","\n","    This function takes preprocessed training and validation inputs/labels, converts\n","    them into PyTorch tensors, and creates DataLoader objects. DataLoaders are used\n","    to iterate over batches of data efficiently during training and validation.\n","\n","    Args:\n","        train_inputs (List or np.array): Tokenized and preprocessed training input data.\n","        val_inputs (List or np.array): Tokenized and preprocessed validation input data.\n","        train_labels (List or np.array): Corresponding labels for the training data.\n","        val_labels (List or np.array): Corresponding labels for the validation data.\n","        batch_size (int, optional): Number of samples per batch. Default is 50.\n","\n","    Returns:\n","        Tuple[DataLoader, DataLoader]:\n","            - train_dataloader (DataLoader): DataLoader for the training data.\n","            - val_dataloader (DataLoader): DataLoader for the validation data.\n","\n","    Notes:\n","        - Training data is shuffled to improve model generalization.\n","        - Validation data is not shuffled to ensure consistent evaluation.\n","    \"\"\"\n","    # Convert datasets to PyTorch tensors\n","    tensor_train_inputs = torch.tensor(train_inputs)\n","    tensor_val_inputs = torch.tensor(val_inputs)\n","    tensor_train_labels = torch.tensor(train_labels)\n","    tensor_val_labels = torch.tensor(val_labels)\n","\n","    # Create TensorDataset objects\n","    train_data = TensorDataset(tensor_train_inputs, tensor_train_labels)\n","    val_data = TensorDataset(tensor_val_inputs, tensor_val_labels)\n","\n","    # Create DataLoaders\n","    train_dataloader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n","    val_dataloader = DataLoader(val_data, shuffle=False, batch_size=batch_size)\n","\n","    return train_dataloader, val_dataloader"]},{"cell_type":"code","execution_count":null,"id":"1fddd0b5","metadata":{"id":"1fddd0b5"},"outputs":[],"source":["train_inputs = input_ids[:training_len]\n","train_labels = labels[:training_len]\n","val_inputs = input_ids[training_len:]\n","val_labels = labels[training_len:]\n","\n","# Load data to PyTorch DataLoader\n","train_dataloader, val_dataloader = \\\n","data_loader(train_inputs, val_inputs, train_labels, val_labels, batch_size=50)"]},{"cell_type":"markdown","id":"24451281","metadata":{"id":"24451281"},"source":["## CNN Model creation"]},{"cell_type":"code","execution_count":null,"id":"c7324ccd","metadata":{"id":"c7324ccd"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class CNN_NLP(nn.Module):\n","    \"\"\"An 1D Convulational Neural Network for Sentence Classification.\"\"\"\n","    def __init__(self,\n","                 pretrained_embedding=None,\n","                 freeze_embedding=False,\n","                 vocab_size=None,\n","                 embed_dim=300,\n","                 filter_sizes=[3, 4, 5],\n","                 num_filters=[100, 100, 100],\n","                 num_classes=2,\n","                 dropout=0.5):\n","        \"\"\"\n","        The constructor for CNN_NLP class.\n","\n","        Args:\n","            pretrained_embedding (torch.Tensor): Pretrained embeddings with\n","                shape (vocab_size, embed_dim)\n","            freeze_embedding (bool): Set to False to fine-tune pretraiend\n","                vectors. Default: False\n","            vocab_size (int): Need to be specified when not pretrained word\n","                embeddings are not used.\n","            embed_dim (int): Dimension of word vectors. Need to be specified\n","                when pretrained word embeddings are not used. Default: 300\n","            filter_sizes (List[int]): List of filter sizes. Default: [3, 4, 5]\n","            num_filters (List[int]): List of number of filters, has the same\n","                length as `filter_sizes`. Default: [100, 100, 100]\n","            n_classes (int): Number of classes. Default: 2\n","            dropout (float): Dropout rate. Default: 0.5\n","        \"\"\"\n","\n","        super(CNN_NLP, self).__init__()\n","        # Embedding layer\n","        if pretrained_embedding is not None:\n","            self.vocab_size, self.embed_dim = pretrained_embedding.shape\n","            self.embedding = nn.Embedding.from_pretrained(pretrained_embedding,\n","                                                          freeze=freeze_embedding)\n","        else:\n","            self.embed_dim = embed_dim\n","            self.embedding = nn.Embedding(num_embeddings=vocab_size,\n","                                          embedding_dim=self.embed_dim,\n","                                          padding_idx=0,\n","                                          max_norm=5.0)\n","        # Conv Network\n","        self.conv1d_list = nn.ModuleList([\n","            nn.Conv1d(in_channels=self.embed_dim,\n","                      out_channels=num_filters[i],\n","                      kernel_size=filter_sizes[i])\n","            for i in range(len(filter_sizes))\n","        ])\n","        # Fully-connected layer and Dropout\n","        self.fc = nn.Linear(np.sum(num_filters), num_classes)\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","    def forward(self, input_ids):\n","        \"\"\"Perform a forward pass through the network.\n","\n","        Args:\n","            input_ids (torch.Tensor): A tensor of token ids with shape\n","                (batch_size, max_sent_length)\n","\n","        Returns:\n","            logits (torch.Tensor): Output logits with shape (batch_size,\n","                n_classes)\n","        \"\"\"\n","\n","        # Get embeddings from `input_ids`. Output shape: (b, max_len, embed_dim)\n","        x_embed = self.embedding(input_ids).float()\n","\n","        # Permute `x_embed` to match input shape requirement of `nn.Conv1d`.\n","        # Output shape: (b, embed_dim, max_len)\n","        x_reshaped = x_embed.permute(0, 2, 1)\n","\n","        # Apply CNN and ReLU. Output shape: (b, num_filters[i], L_out)\n","        x_conv_list = [F.relu(conv1d(x_reshaped)) for conv1d in self.conv1d_list]\n","\n","        # Max pooling. Output shape: (b, num_filters[i], 1)\n","        x_pool_list = [F.max_pool1d(x_conv, kernel_size=x_conv.shape[2])\n","            for x_conv in x_conv_list]\n","\n","        # Concatenate x_pool_list to feed the fully connected layer.\n","        # Output shape: (b, sum(num_filters))\n","        x_fc = torch.cat([x_pool.squeeze(dim=2) for x_pool in x_pool_list],\n","                         dim=1)\n","\n","        # Compute logits. Output shape: (b, n_classes)\n","        logits = self.fc(self.dropout(x_fc))\n","\n","        return logits"]},{"cell_type":"markdown","id":"ebe3dc1e","metadata":{"id":"ebe3dc1e"},"source":["## Optimizer"]},{"cell_type":"code","execution_count":null,"id":"687c1708","metadata":{"id":"687c1708"},"outputs":[],"source":["import torch.optim as optim\n","\n","def initialize_model(pretrained_embedding=None,\n","                    freeze_embedding=False,\n","                    vocab_size=None,\n","                    embed_dim=300,\n","                    filter_sizes=[3, 4, 5],\n","                    num_filters=[100, 100, 100],\n","                    num_classes=2,\n","                    dropout=0.5,\n","                    learning_rate=0.01):\n","    \"\"\"Instantiate a CNN model and an optimizer.\"\"\"\n","\n","    assert (len(filter_sizes) == len(num_filters)), \"filter_sizes and \\\n","    num_filters need to be of the same length.\"\n","\n","    # Instantiate CNN model\n","    print(\"Initializing the model...\")\n","    print(f\"Model parameters:\\n\"\n","          f\"\\tDropout rate: {dropout}\\n\"\n","          f\"\\tLearning rate: {learning_rate}\\n\"\n","          f\"\\tFilters: {filter_sizes}\\n\"\n","          f\"\\tEmbeddings: ({embed_dim}, {vocab_size})\\n\"\n","          f\"\\tNum. filters: {num_filters}\\n\")\n","\n","\n","    # Instantiate CNN model\n","    cnn_model = CNN_NLP(pretrained_embedding=pretrained_embedding,\n","                        freeze_embedding=freeze_embedding,\n","                        vocab_size=vocab_size,\n","                        embed_dim=embed_dim,\n","                        filter_sizes=filter_sizes,\n","                        num_filters=num_filters,\n","                        num_classes=2,\n","                        dropout=0.5)\n","\n","    # Send model to `device` (GPU/CPU)\n","    cnn_model.to(device)\n","\n","    # Instantiate Adadelta optimizer\n","    optimizer = optim.Adadelta(cnn_model.parameters(),\n","                               lr=learning_rate,\n","                               rho=0.95)\n","\n","    return cnn_model, optimizer"]},{"cell_type":"markdown","id":"b1f25ed9","metadata":{"id":"b1f25ed9"},"source":["## Training Loop\n"]},{"cell_type":"code","execution_count":null,"id":"1c1cf6ac","metadata":{"id":"1c1cf6ac"},"outputs":[],"source":["import random\n","import time\n","\n","# Specify loss function\n","loss_fn = nn.CrossEntropyLoss()\n","\n","def set_seed(seed_value=42):\n","    \"\"\"Set seed for reproducibility.\"\"\"\n","\n","    random.seed(seed_value)\n","    np.random.seed(seed_value)\n","    torch.manual_seed(seed_value)\n","    torch.cuda.manual_seed_all(seed_value)\n","\n","from sklearn.metrics import f1_score\n","\n","def evaluate(model, val_dataloader):\n","    \"\"\"Evaluate the model's performance on the validation set after each epoch.\"\"\"\n","    model.eval()\n","\n","    # Tracking variables\n","    val_loss = []\n","    val_preds = []\n","    val_labels = []\n","\n","    # Iterate over validation batches\n","    for batch in val_dataloader:\n","        b_input_ids, b_labels = tuple(t.to(device) for t in batch)\n","\n","        # Disable gradient calculation for evaluation\n","        with torch.no_grad():\n","            logits = model(b_input_ids)\n","\n","        # Compute loss\n","        loss = loss_fn(logits, b_labels)\n","        val_loss.append(loss.item())\n","\n","        # Get predictions\n","        preds = torch.argmax(logits, dim=1).flatten()\n","        val_preds.extend(preds.cpu().numpy())  # Collect predictions\n","        val_labels.extend(b_labels.cpu().numpy())  # Collect true labels\n","\n","    # Compute the F1 score\n","    f1 = f1_score(val_labels, val_preds, average='weighted')  # Use weighted average for multi-class\n","\n","    # Compute the average validation loss\n","    avg_val_loss = np.mean(val_loss)\n","\n","    return avg_val_loss, f1\n","\n","\n","def train(model, optimizer, train_dataloader, val_dataloader=None, epochs=10, early_stopping_patience=5, save_best_model=True):\n","    \"\"\"Train the model with GPU memory optimization, early stopping, and saving the best model.\"\"\"\n","\n","    best_f1 = 0 # Initialize best f1 score\n","    best_val_loss = float('inf')  # Initialize best validation loss as infinity\n","    epochs_no_improve = 0  # Early stopping counter\n","    scaler = GradScaler()  # For mixed precision training\n","    best_model_state = None  # Variable to store best model state\n","\n","    print(\"Start training...\\n\")\n","    print(f\"{'Epoch':^7} | {'Train Loss':^12} | {'Train F1':^9} | {'Val Loss':^10} | {'Val F1':^9} | {'Elapsed':^9}\")\n","    print(\"-\" * 72)\n","\n","    for epoch_i in range(epochs):\n","        # =======================================\n","        #               Training\n","        # =======================================\n","        t0_epoch = time.time()\n","        total_loss = 0\n","        train_preds = []\n","        train_labels = []\n","\n","        model.train()\n","\n","        for step, batch in enumerate(train_dataloader):\n","            b_input_ids, b_labels = tuple(t.to(device) for t in batch)\n","\n","            optimizer.zero_grad()\n","\n","            # Mixed precision forward pass\n","            with autocast():\n","                logits = model(b_input_ids)\n","                loss = loss_fn(logits, b_labels)  # Compute loss\n","\n","            # Backward pass and optimization with mixed precision\n","            scaler.scale(loss).backward()  # Scale loss for mixed precision\n","            scaler.step(optimizer)        # Apply optimizer step\n","            scaler.update()               # Update scaler for next step\n","\n","            total_loss += loss.item()\n","\n","            # Collect training predictions and labels for F1 score\n","            preds = torch.argmax(logits, dim=1).flatten()\n","            train_preds.extend(preds.cpu().numpy())\n","            train_labels.extend(b_labels.cpu().numpy())\n","\n","        # Compute the average training loss and F1 score\n","        avg_train_loss = total_loss / len(train_dataloader)\n","        train_f1 = f1_score(train_labels, train_preds, average='weighted')  # Training F1 score\n","\n","        # =======================================\n","        #               Evaluation\n","        # =======================================\n","        if val_dataloader is not None:\n","            val_loss, val_f1 = evaluate(model, val_dataloader)\n","\n","            # Save the best f1 score\n","            if val_f1 > best_f1:\n","                best_f1 = val_f1\n","\n","            # Save the model with the lowest validation loss\n","            if val_loss < best_val_loss:\n","                best_val_loss = val_loss\n","                epochs_no_improve = 0\n","\n","                # Save the best model state based on the validation loss\n","                if save_best_model:\n","                    best_model_state = model.state_dict()\n","\n","            else:\n","                epochs_no_improve += 1\n","\n","            if epochs_no_improve >= early_stopping_patience:\n","                print(f\"\\nStopping early at epoch {epoch_i + 1}.\")\n","                break\n","\n","        # Print epoch performance\n","        time_elapsed = time.time() - t0_epoch\n","        print(f\"{epoch_i + 1:^7} | {avg_train_loss:^12.4f} | {train_f1:^9.4f} | {val_loss:^10.4f} | {val_f1:^9.4f} | {time_elapsed:^9.2f}\")\n","    else:\n","        # Print training info if no validation data\n","        time_elapsed = time.time() - t0_epoch\n","        print(f\"{epoch_i + 1:^7} | {avg_train_loss:^12.4f} | {train_f1:^9.4f} | {'N/A':^10} | {'N/A':^9} | {time_elapsed:^9.2f}\")\n","\n","    print(\"\\nTraining complete!\")\n","    print(f\"Best F1-score: {best_f1:.3f}\")\n","    print(f\"Best validation loss: {best_val_loss:.3f}\")\n"]},{"cell_type":"markdown","id":"g-d3_0QSNLPK","metadata":{"id":"g-d3_0QSNLPK"},"source":["### CNN-non-static training"]},{"cell_type":"code","execution_count":null,"id":"1jgmPXrCNVlG","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1jgmPXrCNVlG","outputId":"bec681f0-b9e8-4c8d-a23b-bb2dbcebd8d4","executionInfo":{"status":"ok","timestamp":1735604542313,"user_tz":-60,"elapsed":4748796,"user":{"displayName":"Wojciech Neuman","userId":"02532032841570570568"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Initializing the model...\n","Model parameters:\n","\tDropout rate: 0.6\n","\tLearning rate: 0.1\n","\tFilters: [2, 3, 4, 5]\n","\tEmbeddings: (300, 621876)\n","\tNum. filters: [200, 300, 400, 500]\n","\n","Start training...\n","\n"," Epoch  |  Train Loss  | Train F1  |  Val Loss  |  Val F1   |  Elapsed \n","------------------------------------------------------------------------\n","   1    |    0.5160    |  0.7317   |   0.3578   |  0.8502   |  431.98  \n","   2    |    0.3443    |  0.8490   |   0.2896   |  0.8788   |  431.73  \n","   3    |    0.2703    |  0.8860   |   0.2588   |  0.8935   |  431.49  \n","   4    |    0.2229    |  0.9088   |   0.2560   |  0.8930   |  431.25  \n","   5    |    0.1832    |  0.9264   |   0.2708   |  0.8831   |  431.06  \n","   6    |    0.1486    |  0.9418   |   0.2259   |  0.9069   |  431.04  \n","   7    |    0.1226    |  0.9538   |   0.2433   |  0.8995   |  430.82  \n","   8    |    0.0984    |  0.9639   |   0.2333   |  0.9067   |  430.85  \n","   9    |    0.0783    |  0.9733   |   0.2353   |  0.9077   |  430.60  \n","  10    |    0.0644    |  0.9777   |   0.2587   |  0.9015   |  430.87  \n","\n","Stopping early at epoch 11.\n","\n","Training complete!\n","Best F1-score: 0.908\n","Best validation loss: 0.226\n"]}],"source":["set_seed(42)\n","\n","# Initialize hyperparameeters\n","freeze_embedding = False\n","filter_sizes = [2, 3, 4, 5]\n","num_filters = [200, 300, 400, 500]\n","learning_rate = 0.1\n","dropout = 0.6\n","vocab_size = len(word2idx)\n","embed_dim = 300\n","save_best_model = True\n","\n","epochs = 20\n","early_stopping_patience = 5\n","\n","best_model_state = None\n","\n","# Initialize model and optimizer\n","cnn_non_static, optimizer = initialize_model(pretrained_embedding=embeddings_tensor,\n","                                            freeze_embedding=freeze_embedding,\n","                                            vocab_size=vocab_size,\n","                                            embed_dim=embed_dim,\n","                                            learning_rate=learning_rate,\n","                                            filter_sizes=filter_sizes,\n","                                            num_filters=num_filters,\n","                                            dropout=dropout)\n","\n","# Train the model\n","train(cnn_non_static,\n","      optimizer,\n","      train_dataloader,\n","      val_dataloader,\n","      epochs=epochs,\n","      early_stopping_patience=early_stopping_patience,\n","      save_best_model=save_best_model)"]},{"cell_type":"markdown","source":["## Save the model and essential information"],"metadata":{"id":"zmrudb0EotSU"},"id":"zmrudb0EotSU"},{"cell_type":"code","source":["# Save embeddings tensor (pretrained word embeddings)\n","\n","embeddings_tensor_path = '/content/drive/MyDrive/Thesis/Models/LSTM/'\n","torch.save(embeddings_tensor, embeddings_tensor_path)\n","\n","# Save the word2idx dictionary (tokenizer mapping)\n","word2idx_path = os.path.join(drive_path, 'cnn_word2idx.pkl')\n","with open(word2idx_path, 'wb') as file:\n","    pickle.dump(word2idx, file)\n","\n","# Save max_len (maximum length of sequences)\n","max_len_path = os.path.join(drive_path, 'cnn_max_len.pkl')\n","with open(max_len_path, 'wb') as file:\n","    pickle.dump(max_len, file)\n","\n","# Save the best model during training with the highest F1 score\n","best_model_path = os.path.join(drive_path, 'cnn_best_model.pth')\n","if save_best_model and best_model_state is not None:\n","    torch.save(best_model_state, best_model_path)\n","else:\n","    torch.save(cnn_non_static.state_dict(), best_model_path)\n","\n","# Save the CNN model parameters as a JSON file\n","model_params = {\n","    'vocab_size': vocab_size,\n","    'embedding_dim': embed_dim,\n","    'dropout': dropout,\n","    'filter_sizes': filter_sizes,\n","    'num_filters': num_filters\n","}\n","params_save_path = os.path.join(drive_path, 'cnn_model_params.json')\n","with open(params_save_path, 'w') as f:\n","    json.dump(model_params, f, indent=4)\n","\n","print(f\"Model parameters saved to: {params_save_path}\")\n","\n","# Output paths to confirm the saving\n","print(f\"Embeddings tensor saved to: {embeddings_tensor_path}\")\n","print(f\"word2idx saved to: {word2idx_path}\")\n","print(f\"max_len saved to: {max_len_path}\")\n","print(f\"Best CNN model saved to: {best_model_path}\")\n","print(f\"CNN Model parameters saved to: {params_save_path}\")"],"metadata":{"id":"bEyrCtLztFxO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1735604545580,"user_tz":-60,"elapsed":3378,"user":{"displayName":"Wojciech Neuman","userId":"02532032841570570568"}},"outputId":"838984a1-2cce-46a1-b510-e6be1ffc143a"},"id":"bEyrCtLztFxO","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model parameters saved to: /content/drive/MyDrive/Thesis/Models/CNN/cnn_model_params.json\n","Embeddings tensor saved to: /content/drive/MyDrive/Thesis/Models/CNN/cnn_embeddings_tensor.pth\n","word2idx saved to: /content/drive/MyDrive/Thesis/Models/CNN/cnn_word2idx.pkl\n","max_len saved to: /content/drive/MyDrive/Thesis/Models/CNN/cnn_max_len.pkl\n","Best CNN model saved to: /content/drive/MyDrive/Thesis/Models/CNN/cnn_best_model.pth\n","CNN Model parameters saved to: /content/drive/MyDrive/Thesis/Models/CNN/cnn_model_params.json\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"14S0ELAmQLBrqkVe41Xw-P0y0kqR8Zzf9","timestamp":1737635063110},{"file_id":"1iLCEvxGwc3ICHGDMih9cJZ0gFuqPMkGS","timestamp":1735598337869},{"file_id":"1YTX5OpB2mQK5THOSogqDA13nW2JCTa8v","timestamp":1735294500861},{"file_id":"1KONv0rDL55qXFbUPM6_SDhBYknAIbNUk","timestamp":1734915962197}],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}